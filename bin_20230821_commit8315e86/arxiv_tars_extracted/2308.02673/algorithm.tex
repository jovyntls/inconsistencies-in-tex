%
\section{New Algorithm}
%
We now specify Algorithm~2 to replace Algorithm~1 in \cite{b1}. In
doing so, not only do we incorporate Lemma~2 instead of Lemma~1 but
also we eliminate the many uncertainties present in Algorithm~1 of
\cite{b1}.

\setcounter{algorithm}{1}
\begin{algorithm}
\caption{Update for Algorithm~1}\label{alg:alg2}
\begin{algorithmic}[1]
%\Require $n \geq 0$
%\Ensure $y = x^n$
\State {\bf Initialization:} Compute %$\{ s_{nk} \}$ such that
$s_{nk}=e^{j(\alpha_n + (k -0.5)\omega)}$ for $n=1,2,\ldots,N$ and
$k=1,2,\ldots,K$.
\State Eliminate duplicates among $s_{nk}$ and sort to get
$0\le \lambda_1 < \lambda_2 < \cdots < \lambda_L < 2\pi.$
\State Let, for $l = 1,2,\ldots,L,$ ${\cal N} (\lambda_l) =
\{ n | s_{nk} = \lambda_l \}.$
\State %Consider ${\rm arc}(\lambda_L : \lambda_1)$, note $\phase{\mu}=0$ is inside this arc.
Set $\phase{\mu} = 0$. For $n=1,2,\ldots,N$, calculate
$\theta_n = \arg\max_{\theta_n\in\Phi_K} \cos(\theta_n + \alpha_n - \phase{\mu})$.
\State Set $g_1 = h_0 + \sum_{n=1}^N h_ne^{j\theta_n}$, ${\tt absgmax} = 0$.
\For{$l = 2, 3, \ldots, L$}
\State For each $n\in{\cal N}(\lambda_l)$, let $(\theta_n + \omega \leftarrow \theta_n) \!\! \mod \Phi_K$.
\State Let
\[
g_l = g_{l-1} + \sum_{n\in {\cal N}(\lambda_l)} h_n \big(e^{j\theta_n} - e^{j(\theta_n - \omega) \!\!\!\! \mod \Phi_K}\big)
\]
\If{$|g_l| > {\tt absgmax}$}
\State Let ${\tt absgmax} = |g_l|$
\State Store $\theta_n$ for $n=1,2,\ldots,N$
\EndIf
\EndFor
\State Read out $\theta_n^*$ as the stored $\theta_n$, $n=1,2,\ldots,N$.
\end{algorithmic}
\end{algorithm} 