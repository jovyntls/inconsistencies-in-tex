% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{wan2021convergence}
S.~Wan, J.~Lu, P.~Fan, Y.~Shao, C.~Peng, and K.~B. Letaief, ``Convergence analysis and system design for federated learning over wireless networks,'' \emph{IEEE J. Sel. Areas Commun.}, vol.~39, no.~12, pp. 3622--3639, Oct. 2021.

\bibitem{xing2021federated}
H.~Xing, O.~Simeone, and S.~Bi, ``Federated learning over wireless device-to-device networks: Algorithms and convergence analysis,'' \emph{IEEE J. Sel. Areas Commun.}, vol.~39, no.~12, pp. 3723--3741, Oct. 2021.

\bibitem{xing2020decentralized}
H.~\vspace{0mm}Xing, O.~Simeone, and S.~Bi, ``Decentralized federated learning via {SGD} over wireless {D2D} networks,'' in \emph{Proc. IEEE 21st Int. Workshop Signal Process. Adv. Wireless Commun. (SPAWC)}, May 2020, pp. 1--5.

\bibitem{amiri2020machine}
M.~M. Amiri and D.~G{\"u}nd{\"u}z, ``Machine learning at the wireless edge: Distributed stochastic gradient descent over-the-air,'' \emph{IEEE Trans. Signal Process.}, vol.~68, pp. 2155--2169, Mar. 2020.

\bibitem{caldas2018leaf}
S.~Caldas, S.~M.~K. Duddu, P.~Wu, T.~Li, J.~Kone{\v{c}}n{\`y}, H.~B. McMahan, V.~Smith, and A.~Talwalkar, ``Leaf: A benchmark for federated settings,'' \emph{arXiv preprint arXiv:1812.01097}, Dec. 2018.

\bibitem{bonawitz2019towards}
K.~Bonawitz, H.~Eichner, W.~Grieskamp, D.~Huba, A.~Ingerman, V.~Ivanov, C.~Kiddon, J.~Kone{\v{c}}n{\`y}, S.~Mazzocchi, B.~McMahan \emph{et~al.}, ``Towards federated learning at scale: System design,'' \emph{arXiv preprint arXiv:1902.01046}, Feb. 2019.

\bibitem{FedCP-QQ}
P.~Humbert, B.~Le~Bars, A.~Bellet, and S.~Arlot, ``One-shot federated conformal prediction,'' in \emph{Proc. Int. Conf. Mach. Learn.}, Jul. 2023, pp. 14\,153--14\,177.

\bibitem{Tong_TBMA}
G.~Mergen and L.~Tong, ``Type based estimation over multiaccess channels,'' \emph{IEEE Trans. Signal Process.}, vol.~54, no.~2, pp. 613--626, Jan. 2006.

\bibitem{Liu_TBMA}
K.~Liu and A.~M. Sayeed, ``Asymptotically optimal decentralized type-based detection in wireless sensor networks,'' in \emph{Proc. IEEE Int. Conf. Acoust., Speech, Signal Process}, May 2004, pp. iii--873.

\bibitem{FedCP-Avg}
C.~Lu and J.~Kalpathy-Cramer, ``Distribution-free federated learning with conformal predictions,'' \emph{arXiv preprint arXiv:2110.07661}, Oct. 2021.

\bibitem{lu2023federated}
C.~Lu, Y.~Yu, S.~P. Karimireddy, M.~I. Jordan, and R.~Raskar, ``Federated conformal predictors for distributed uncertainty quantification,'' in \emph{Proc. Int. Conf. Mach. Learn.}, Jul. 2023, pp. 22\,942--22\,964.

\bibitem{luo2016quantiles}
G.~Luo, L.~Wang, K.~Yi, and G.~Cormode, ``Quantiles over data streams: {Experimental} comparisons, new analyses, and further improvements,'' \emph{The VLDB Journal}, vol.~25, pp. 449--472, Feb. 2016.

\bibitem{dunning2021t}
T.~Dunning, ``The t-digest: Efficient estimates of distributions,'' \emph{Softw. Impacts}, vol.~7, no. 100049, Feb. 2021.

\bibitem{plassier2023conformal}
V.~Plassier, M.~Makni, A.~Rubashevskii, E.~Moulines, and M.~Panov, ``Conformal prediction for federated uncertainty quantification under label shift,'' \emph{arXiv preprint arXiv:2306.05131}, Jun. 2023.

\bibitem{tibshirani2019conformal}
R.~J. Tibshirani, R.~Foygel~Barber, E.~Candes, and A.~Ramdas, ``Conformal prediction under covariate shift,'' in \emph{Proc. Adv. Neural Inf. Process. Syst}, vol.~32, 2019, pp. 2526--2536.

\bibitem{multi_cell_FRAN}
R.~Kassab, O.~Simeone, and P.~Popovski, ``Information-centric grant-free access for {IoT} {Fog} networks: Edge vs. cloud detection and learning,'' \emph{IEEE Trans. Wirel. Commun.}, vol.~19, no.~10, pp. 6347--6361, Oct. 2020.

\bibitem{single_cell_codebook}
J.~Dommel, Z.~Utkovski, S.~Sta{\'n}czak, and O.~Simeone, ``Joint source-channel coding and bayesian message passing detection for grant-free radio access in {IoT},'' in \emph{Proc. IEEE Int. Conf. Acoust., Speech, Signal Process.}, May 2020, pp. 8574--8578.

\bibitem{multi_cell_codebook}
J.~Dommel, Z.~Utkovski, O.~Simeone, and S.~Sta{\'n}czak, ``Joint source-channel coding for semantics-aware grant-free radio access in {IoT} {Fog} networks,'' \emph{IEEE Signal Process. Lett.}, vol.~28, pp. 728--732, Apr. 2021.

\bibitem{zhu2023information}
M.~Zhu, C.~Feng, C.~Guo, N.~Jiang, and O.~Simeone, ``Information bottleneck-inspired type based multiple access for remote estimation in iot systems,'' \emph{IEEE Signal Process. Lett.}, vol.~30, pp. 403--407, Apr. 2023.

\bibitem{vovk2005algorithmic}
V.~Vovk, A.~Gammerman, and G.~Shafer, \emph{Algorithmic learning in a random world}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2005, vol.~29.

\bibitem{mcmahan2017communication}
B.~McMahan, E.~Moore, D.~Ramage, S.~Hampson, and B.~A. y~Arcas, ``Communication-efficient learning of deep networks from decentralized data,'' in \emph{Proc. Int. Conf. Artif. Intell. Stat. (AISTATS)}, vol.~54, Apr. 2017, pp. 1273--1282.

\bibitem{bai2021don}
Y.~Bai, S.~Mei, H.~Wang, and C.~Xiong, ``Donâ€™t just blame over-parametrization for over-confidence: Theoretical analysis of calibration in binary classification,'' in \emph{Proc. Int. Conf. Mach. Learn.}, Jul. 2021, pp. 566--576.

\bibitem{guo2017calibration}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger, ``On calibration of modern neural networks,'' in \emph{Proc. Int. Conf. Mach. Learn.}, Aug. 2017, pp. 1321--1330.

\bibitem{cohen2022calibrating}
K.~M. Cohen, S.~Park, O.~Simeone, and S.~Shamai, ``Calibrating {AI} models for wireless communications via conformal prediction,'' \emph{arXiv preprint arXiv:2212.07775}, Dec. 2022.

\bibitem{liu2020privacy}
D.~Liu and O.~Simeone, ``Privacy for free: Wireless federated learning via uncoded transmission with adaptive power control,'' \emph{IEEE J. Sel. Areas Commun.}, vol.~39, no.~1, pp. 170--185, Nov. 2020.

\bibitem{zhu2019broadband}
G.~Zhu, Y.~Wang, and K.~Huang, ``Broadband analog aggregation for low-latency federated edge learning,'' \emph{IEEE Trans. Wirel. Commun.}, vol.~19, no.~1, pp. 491--506, Jan. 2020.

\bibitem{yang2020federated}
K.~Yang, T.~Jiang, Y.~Shi, and Z.~Ding, ``Federated learning via over-the-air computation,'' \emph{IEEE Trans. Wirel. Commun.}, vol.~19, no.~3, pp. 2022--2035, Mar. 2020.

\bibitem{angelopoulos2021gentle}
A.~N. Angelopoulos and S.~Bates, ``A gentle introduction to conformal prediction and distribution-free uncertainty quantification,'' \emph{arXiv preprint arXiv:2107.07511}, Jul. 2021.

\bibitem{barber2021predictive}
R.~F. Barber, E.~J. Candes, A.~Ramdas, and R.~J. Tibshirani, ``Predictive inference with the jackknife+,'' \emph{Ann. Statist.}, vol.~49, no.~1, pp. 486--507, Feb. 2021.

\bibitem{romano2020classification}
Y.~Romano, M.~Sesia, and E.~Candes, ``Classification with valid and adaptive coverage,'' \emph{Adv. Neural Inf. Process. Syst.}, vol.~33, pp. 3581--3591, Dec. 2020.

\bibitem{wang2022probabilistic}
Z.~Wang, R.~Gao, M.~Yin, M.~Zhou, and D.~M. Blei, ``Probabilistic conformal prediction using conditional random samples,'' \emph{arXiv preprint arXiv:2206.06584}, Jun. 2022.

\bibitem{teng2022predictive}
J.~Teng, C.~Wen, D.~Zhang, Y.~Bengio, Y.~Gao, and Y.~Yuan, ``Predictive inference with feature conformal prediction,'' \emph{arXiv preprint arXiv:2210.00173}, Oct. 2022.

\bibitem{chen2023spikecp}
J.~Chen, S.~Park, and O.~Simeone, ``Spikecp: Delay-adaptive reliable spiking neural networks via conformal prediction,'' \emph{arXiv preprint arXiv:2305.11322}, May 2023.

\bibitem{lei2014distribution}
J.~Lei and L.~Wasserman, ``Distribution-free prediction bands for non-parametric regression,'' \emph{Journal of the Royal Statistical Society: Series B: Statistical Methodology}, vol.~76, no.~1, pp. 71--96, Jan. 2014.

\bibitem{polyanskiy2010channel}
Y.~Polyanskiy, H.~V. Poor, and S.~Verd{\'u}, ``Channel coding rate in the finite blocklength regime,'' \emph{IEEE Trans. Inf. Theory}, vol.~56, no.~5, pp. 2307--2359, May 2010.

\bibitem{renyi1961measures}
A.~R{\'e}nyi, ``On measures of entropy and information,'' in \emph{Proc. 4th Berkeley Symp. Math. Statist. Prob.}, vol.~4, 1961, pp. 547--562.

\bibitem{angelopoulos2022private}
A.~N. Angelopoulos, S.~Bates, T.~Zrnic, and M.~I. Jordan, ``Private prediction sets,'' \emph{Harvard Data Science Review}, vol.~4, no.~2, Apr. 2022.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern Recognit.}, Jul. 2016, pp. 770--778.

\bibitem{wald2004sequential}
A.~Wald, \emph{Sequential analysis}.\hskip 1em plus 0.5em minus 0.4em\relax Courier Corporation, 2004.

\end{thebibliography}
