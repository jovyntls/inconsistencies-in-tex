\documentclass[conference,letterpaper]{IEEEtran}

\usepackage{etex}

\def\papertitle{Unrolled and Pipelined Decoders based on Look-Up Tables for Polar Codes}

\pdfminorversion=4
\usepackage[draft,pdfborder={0 0 0}]{hyperref}

\pdfinfo{%
  /Author (Pascal Giard, Syed Aizaz Ali Shah, Alexios Balatsoukas-Stimming, Maximilian Stark, and Gerhard Bauch)
  /Title (\papertitle)
}

\renewcommand*{\figureautorefname}{Fig.} % We want Fig. for short instead of Figure
% IEEE favors capital S for section references, so override what autoref uses
\renewcommand{\sectionautorefname}{Section}

\usepackage{graphicx}
\usepackage[cmex10]{amsmath}
\usepackage{amsthm,amsfonts,amssymb}
\usepackage{bm} % bold face for math
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{tikz,pgfplots}
\usetikzlibrary{shapes,positioning,arrows,decorations.markings,fit,patterns,arrows.meta,calc,mux,circuits.logic.US,spy}
\pgfplotsset{compat=1.18}

\usepackage{xcolor}
\usepackage{balance}
\usepackage{xfrac} % for \sfrac

\usepackage{glossaries} % For acronyms

\newcommand{\sgn}[1]{\text{sgn}(#1)}
\newcommand{\mvec}[1]{\bm{#1}}

% Register shapes
\input{figures/register.tex} 
\input{figures/register_dotted.tex}

\begin{document}

% More than 3 authors? Use "et al."
\bstctlcite{IEEEexample:BSTcontrol}

\newacronym{sc}{SC}{successive-cancellation}
\newacronym{ssc}{SSC}{simplified successive-cancellation}
\newacronym{scl}{SCL}{successive-cancellation list}
\newacronym{ca-scl}{CA-SCL}{CRC-aided \gls{scl}}
\newacronym[plural=CCs,firstplural=clock cycles (CCs)]{cc}{CC}{clock cycle}
\newacronym{llr}{LLR}{log-likelihood ratio}
\newacronym{lut}{LUT}{look-up table}
\newacronym{bpsk}{BPSK}{binary phase-shift keying}
\newacronym{awgn}{AWGN}{additive white Gaussian noise}
\newacronym{fer}{FER}{frame-error rate}
\newacronym{ber}{BER}{bit-error rate}
\newacronym{par}{PAR}{place-and-route}
\newacronym{ib}{IB}{information bottleneck}
\newacronym{msb}{MSB}{most-significant bit}

\title{\papertitle}

\author{\IEEEauthorblockN{Pascal Giard\IEEEauthorrefmark{1}, Syed Aizaz Ali Shah\IEEEauthorrefmark{2}, Alexios Balatsoukas-Stimming\IEEEauthorrefmark{4}, Maximilian Stark\IEEEauthorrefmark{2}, and Gerhard Bauch\IEEEauthorrefmark{2}}
  \IEEEauthorblockA{\IEEEauthorrefmark{1}LaCIME, \'Ecole de technologie sup\'erieure, Montr\'eal, Qu\'ebec, Canada.}
  \IEEEauthorblockA{\IEEEauthorrefmark{2}Institute of Communications, Hamburg University of Technology, Germany.}
  \IEEEauthorblockA{\IEEEauthorrefmark{4}Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands.}
  Email: pascal.giard@etsmtl.ca, aizaz.shah@tuhh.de, a.k.balatsoukas.stimming@tue.nl, \{maximilian.stark, bauch\}@tuhh.de}%

\maketitle

\begin{abstract} Unrolling a decoding algorithm allows to achieve extremely high throughput at the cost of increased area. \Glspl{lut} can be used to replace functions otherwise implemented as circuits. In this work, we show the impact of replacing blocks of logic by carefully crafted \glspl{lut} in unrolled decoders for polar codes. We show that using \glspl{lut} to improve key performance metrics (e.g., area, throughput, latency) may turn out more challenging than expected. We present three variants of \gls{lut}-based decoders and describe their inner workings as well as circuits in detail. The \gls{lut}-based decoders are compared against a regular unrolled decoder, employing fixed-point representations for numbers, with a comparable error-correction performance. A short systematic polar code is used as an illustration. All resulting unrolled decoders are shown to be capable of an information throughput of little under 10\,Gbps in a 28\,nm FD-SOI technology clocked in the vicinity of 1.4\,GHz to 1.5\,GHz. The best variant of our \gls{lut}-based decoders is shown to reduce the area requirements by 23\% compared to the regular unrolled decoder while retaining a comparable error-correction performance.
\end{abstract}

% Reset the acronyms' definitions after the abstract
\glsresetall

\section{Introduction}\label{sec:intro}
Unrolled decoders are known for their extremely high throughput \cite{Schlafer2013,Balatsoukas-Stimming2015,Giard_TCASI_2016,Giard_JETCAS_2017}. In particular, they offer at least one order of magnitude improvement in throughput with respect to standard decoders at the cost of larger area requirements. While this unrolling technique has been applied to \gls{sc}-based polar decoders before, e.g., \cite{Giard_TCASI_2016,Giard_JETCAS_2017}, it has not yet been combined with \gls{lut}-based decoding that has the potential to reduce the required quantization bit-width and, hence, the area and power consumption of the decoder.

\subsubsection*{Contributions}
In this paper, we describe the design and implementation of unrolled and pipelined \gls{lut}-based hardware decoders for polar codes. We present three different variants and provide results for all three, along with results for a regular fixed-point decoder, illustrating the challenges of realizing the \gls{lut}-based decoders in hardware. In the end, we show that, even for a short $(128, 64)$ polar code, a \gls{lut}-based decoder can reduce the area requirements by 23\% while matching the error-correction performance and exceeding the throughput of a decoder using a standard fixed-point representation.


\subsubsection*{Outline} 
The remainder of this paper starts with \autoref{sec:bg} that provides the necessary background, consisting of a brief review of polar codes and an introduction to the \gls{sc} and \gls{ssc} decoding algorithms. Moreover, the concept of unrolled and pipelined hardware architectures is presented as well as that of using \glspl{lut} to implement functions. \autoref{sec:gen} describes our adaptation of the fully-unrolled and pipelined hardware architecture to \gls{lut}-based decoding. In particular, the generation of the \glspl{lut}, the architectures, and the decoders are discussed. \autoref{sec:impl} discusses implementation details and provides post-synthesis ASIC area and timing results using the 28\,nm FD-SOI CMOS technology from ST Microelectronics. 
Finally, \autoref{sec:conclusion} concludes this paper.


\section{Background}\label{sec:bg}
\subsection{Encoding of Polar Codes}\label{sec:bg:enc}
In matrix form, a polar code of length $N$ can be obtained as $\mvec{x} {=} \mvec{u}\mvec{F}^{\otimes n}$, where $\mvec{F} {=} \left[ \begin{smallmatrix} 1 & 0 \\ 1 & 1 \end{smallmatrix} \right]$, $n \triangleq \log _2 N$, $\mvec{u}$ is the vector of bits to be encoded, and $\mvec{F}^{\otimes n}$ is the $n^{\text{th}}$ Kronecker product of $\mvec{F}$ and $\mvec{F}^{\otimes 1}{=}\mvec{F}$. To obtain an $(N,\,k)$ polar code of rate $R=\sfrac{k}{N}$, the $k$ most-reliable bit locations in $\mvec{u}$ are used to hold the information bits while the other $N{-}k$ bits, called frozen bits, are set to a predetermined value (usually 0). The bit-location reliabilities depend on the channel type and condition.

The encoding process can also be represented as a graph like that of Fig.\,\ref{fig:pc8}, where $\oplus$ represents modulo-2 addition (XOR). In that representation, a codeword is generated by setting the frozen-bit locations (the $u_0$ to $u_2$ in light gray) to 0 and the information-bit locations (the $u_3$ to $u_7$ in black) to the message to be encoded, and by propagating the data through the graph, from left to right. As described in \cite{Sarkis_TCOMM_2015}, systematic encoding can be carried out by feeding the output values ($x_0$ to $x_7$) into the left-hand side, resetting the frozen-bit locations to 0, and propagating the data through the graph again.

\subsection{Successive-Cancellation Decoding and Simplified Successive-Cancellation Decoding}\label{sec:bg:sc}
\begin{figure}[t]
  \begin{minipage}{0.6\columnwidth}
    \centering
    \subfloat[Graph]{\label{fig:pc8}\hspace{-15pt}\resizebox{\columnwidth}{!}{\input{figures/pc8.tex}}}
  \end{minipage}%
  \begin{minipage}{0.38\columnwidth}
    \centering
    \subfloat[SC Decoder Tree]{\label{fig:sc-tree}\resizebox{0.9\columnwidth}{!}{\rotatebox{90}{\input{figures/sc-tree.tex}}}}
    \vspace{-11pt}
    \subfloat[SSC Decoder Tree]{\makebox[\columnwidth][c]{\label{fig:ssc-tree}\resizebox{0.7\columnwidth}{!}{\rotatebox{90}{\input{figures/ssc-tree.tex}}}}}
  \end{minipage}
  \caption{Graph and decoder-tree representations of an $(8,\,5)$ polar code.}
  \label{fig:pc_8_5}
\end{figure}

The \gls{sc} decoding algorithm was proposed in the seminal work that introduced polar codes~\cite{ArikanFirst}. Illustrating its execution using a decoder-tree representation, it proceeds by visiting the tree---e.g., Fig.~\ref{fig:sc-tree}---sequentially, from top to bottom, from left to right, successively estimating $\bm{\hat{u}}$ at the leaf nodes, from the noisy channel values. Visiting a left edge (blue) on this representation, the \gls{sc} algorithm can calculate the soft-input \glspl{llr} $\alpha_l$ to the child node with the min-sum approximation \cite{Leroux2011}
\begin{equation}\label{eqn:sc:f}
\alpha_l[i] = \sgn{\alpha_v[i]\alpha_v[i + \sfrac{N_v}{2}]} \min(|\alpha_v[i]|, |\alpha_v[i + \sfrac{N_v}{2}]|),
\end{equation}
where $\alpha_v$ and $N_v$ are respectively the \glspl{llr} and node length from the parent node, and $\sgn{x}$ returns $-1$ when $x<0$, $+1$ otherwise. At the root node, the channel \glspl{llr} are used. Once a leaf node is reached, a bit $\hat{u}_i$ (for a non-systematic polar code) is estimated as
\begin{equation}\label{eqn:sc:estu}
\hat{u}_i = \begin{cases}
0\text{,} & \text{when } \alpha_v \geq 0~\text{or}~i \in \mathcal{F};\\
1\text{,} & \text{otherwise,}
\end{cases}
\end{equation}
where $\mathcal{F}$ is the set of frozen-bit indices. For a systematic polar code under \gls{sc} decoding, the estimated-bit vector can be obtained at the end of the decoding process by calculating $\mvec{\hat{u}}\mvec{F}^{\otimes n}$ or its equivalent.

Visiting a right edge (red), the \glspl{llr} $\alpha_r$ to the child node can be calculated \cite{Leroux2011} as
\begin{equation}\label{eqn:sc:g}
\alpha_r[i] = \begin{cases}
\alpha_v[i + \sfrac{N_v}{2}] + \alpha_v[i]\text{,} & \text{when } \beta_l[i] = 0;\\
\alpha_v[i + \sfrac{N_v}{2}] - \alpha_v[i]\text{,} & \text{otherwise},
\end{cases}
\end{equation}
where $\beta_l$ is the bit-estimate vector generated by the left sibling in the decoder-tree. If the left sibling is a leaf node, its estimated-bit value $\hat{u}_i$ is used as the $\beta_l$. Otherwise, the estimated-bit vector $\beta_v$ at a node $v$ is calculated as
\begin{equation}\label{eqn:sc:combine}
\beta_v[i] =
  \begin{cases}
    \beta_l[i]\oplus \beta_r[i], & \text{when}~i < \sfrac{N_v}{2}\\
    \beta_r[i+\sfrac{N_v}{2}], & \text{otherwise},
  \end{cases}
\end{equation}
where $\beta_l$ and $\beta_r$ are the bit-estimate vectors from the left- and right-child nodes, respectively.

The \gls{ssc} algorithm is a variant that exploits the fact that subtrees solely composed of either frozen (rate-0 codes) or information nodes (rate-1 codes) do not need to be fully traversed \cite{Alamdar-Yazdi2011}. 
Fig.\,\ref{fig:ssc-tree} shows a decoder tree for the $(8,\,5)$ polar code of Fig.\,\ref{fig:pc8}, where the \gls{ssc} algorithm is applied, i.e., the tree of Fig.\,\ref{fig:sc-tree} is pruned by recognizing that part of its left-hand-side subtree is a rate-0 code and that the right-hand-side subtree is a rate-1 code.
In Fig.\,\ref{fig:ssc-tree}, the former subtree is replaced by a white node and the latter with a black node. Both cases are direct applications of \eqref{eqn:sc:estu}, i.e., the estimated bit vector for a rate-0 code is always the all-zero vector and that of a rate-1 code is composed of hard decisions on the \glspl{llr} as it does not contain any redundancy.

\subsection{Unrolled and Pipelined Hardware Architectures}\label{sec:bg:unrolled}
\begin{figure}[t]
  \centering
  \resizebox{\columnwidth}{!}{\input{figures/unrolled_deeply_arch_8_5.tex}}
  \caption{Fully-unrolled deeply-pipelined decoder for a systematic (8, 5) polar code. Clock signals omitted for clarity. CC stands for \glsentrylong{cc}.}
  \label{fig:unrolled_deeply_arch_8_5}
\end{figure}

Unrolled decoder architectures provide extremely high decoding speeds. In an unrolled decoder architecture, each and every operation required is instantiated in hardware so that data can flow through the decoder with minimal control. 

\begin{table}[t]
\centering
\caption{Block types used in the unrolled decoders.}
\begin{tabular}{cl}
  \toprule
  \textbf{Name} & \textbf{Description}\\
  \midrule
  $f$ & Application of \eqref{eqn:sc:f}\vspace{2pt}\\
  $g$ & Application of \eqref{eqn:sc:g}\vspace{2pt}\\
  $g_{0R}$ & Application of \eqref{eqn:sc:g}, where $\mvec{\beta_l}$ is an all-zero vector\vspace{2pt}\\
  $I$ & Application of \eqref{eqn:sc:estu}, note that $i \notin \mathcal{F}$\vspace{2pt}\\
  $C$ & Application of \eqref{eqn:sc:combine}\vspace{2pt}\\
  $C_{0R}$ & Application of \eqref{eqn:sc:combine}, where $\mvec{\beta_l}$ is an all-zero vector\vspace{2pt}\\
  \bottomrule
\end{tabular}
\label{tab:block-types}
%\vspace{-10pt}
\end{table}

\autoref{fig:unrolled_deeply_arch_8_5} shows a fully-unrolled and deeply-pipelined decoder for the $(8,5)$ polar code illustrated in \autoref{fig:pc_8_5}. Data flows from left to right. The $\alpha$ and $\beta$ blocks illustrated in light blue are registers storing \glspl{llr} or bit estimates, respectively. White blocks are the functions described in \autoref{tab:block-types} and dotted registers are regular registers; they will be referred to when discussing partial pipelining in the following. As the $C_{0R}$ and $I$ blocks do not contain logic, i.e., they are equivalent to wires, they are inserted as preprocessing and postprocessing blocks, respectively. Among the registers, three are needed to retain the channel \glspl{llr}, denoted by $\alpha_c$ in the figure, during the $2^\text{nd}$, $3^\text{rd}$, and $4^{\text{th}}$ \glspl{cc}. Such unrolled architectures for polar decoders were described at length in \cite{Giard_TCASI_2016}.

\subsubsection*{Deeply Pipelined Vs Partially Pipelined}
In a deeply-pipelined architecture such as that illustrated in \autoref{fig:unrolled_deeply_arch_8_5}, a new frame is loaded into the decoder at every clock cycle. Therefore, a new estimated codeword is also output at each clock cycle. At any point in time, there are as many frames being decoded as there are pipeline stages. This leads to a very high throughput at the cost of high memory requirements.

Partial pipelining, on the other hand, allows to reduce the required area, at the cost of reducing the throughput, by removing redundant registers in parts of the pipeline where data remains unchanged over multiple clock cycles \cite{Giard_TCASI_2016}. Removing the dotted registers in \autoref{fig:unrolled_deeply_arch_8_5} results in an initiation interval of 2, meaning that at every second clock cycle, a new frame can be fed into the decoder and a new codeword is estimated. We note that the interval only affects the memory, not the computational elements, in the decoder.

\subsection{Functions as Look-up Tables}\label{sec:bg:lut}
A \gls{lut} is a type of memory that maps a set of input values to output values. It can provide quick access to precomputed values that would otherwise require complex calculations. In the same vein, \glspl{lut} can also be used to approximate mathematical functions.  
In this work, we use the expression \emph{\gls{lut}-based decoders} to refer to decoders in which arithmetic computations are replaced with look-up operations of integer-valued messages\cite{shah_coarsely_2019,Koike-Akino2019}. 
The reliability information is embedded in the integer valued messages stored in the \glspl{lut}. We carefully craft \glspl{lut} to replace the logic that would normally go into the $f$ and $g$ functions of \autoref{tab:block-types}, where the $g$ \glspl{lut} are also used for $g_{0R}$. Details regarding the design of these \glspl{lut} are given in the next section.

\section{Unrolled and Pipelined LUT-based Simplified Successive-Cancellation Decoding}\label{sec:gen}
\subsection{Look-up Table Generation}\label{sec:gen:lut}
\input{LUT_generation}

\subsection{Unrolled-Architecture Generation}\label{sec:gen:unrolled}
The hardware implementations are generated using our software toolchain, first mentioned in \cite{Sarkis2014a} but significantly improved over the years to extend its functionality, including to generate hardware unrolled decoders \cite{Giard_TCASI_2016}. For this work, we further modified it in order to add support for substituting the $f$, $g$, $g_{0R}$ functions of \autoref{tab:block-types} by \glspl{lut}.

Our toolchain notably takes a polar code construction as well as a configuration file as input, and from that, it optimizes the decoder tree, e.g., going from the decoder tree of Fig.\,\ref{fig:sc-tree} to that of Fig.\,\ref{fig:ssc-tree}, and then generates the decoder. Among the configurable options are the code length, rate, the types of nodes that can be used, and the type of decoder. The type of nodes dictates the decoding algorithm. For this work, we generate hardware unrolled decoders in VHDL that implement the \gls{ssc} algorithm.

\section{Implementation and Results}\label{sec:impl}

In this section, we present implementation results for various \gls{lut}-based unrolled decoders. A fixed-point unrolled decoder is used for reference. Our decoders target a systematic $(128,64)$ polar code optimized for $\sfrac{E_b}{N_0}=3.0$\,dB using the method of Tal and Vardy \cite{Tal2011a}, and have an initiation interval of $10$ and a fixed latency of 86\,\glsentrylongpl{cc}. Without loss of generality, systematic coding is used as it offers better \gls{ber} performance than non-systematic coding at the cost of a negligible complexity increase. The quantization used for the fixed-point decoder was determined by way of simulation with bit-true models.
We denote quantization as $Q_i$.$Q_c$, where $Q_c$ is the total number of bits used to store a channel \gls{llr} and $Q_i$ is the total the number of bits used to store an internal \gls{llr}.
All \glspl{llr} use 2's complement representation.
All \gls{lut}-based decoders were designed for $\sfrac{E_b}{N_0}=3.0$\,dB and $|\mathcal{T}|=16$, i.e, 4-bit resolution.

\subsection{Functional Blocks in \gls{lut}-based Decoders}
This section presents how the block types of \autoref{tab:block-types} were adapated to the \gls{lut}-based decoders.

The circuits implementing the $C$ and $C_{0R}$ blocks are identical to the fixed-point decoder. The $I$ blocks are similar to those of the fixed-point decoder, with an added inverter per bit. It corresponds to a series of inverters that take the \gls{msb} of the soft messages $\mvec{\alpha}$ or the integer messages $\mvec{t}$ as input. 

The $g$ and $g_{0R}$ blocks are realized by the synthesis tools as logic circuits according to the truth table of corresponding \glspl{lut} in the three \gls{lut}-based decoders. In the \gls{ib} decoder, the ${f}$ blocks are realized in the same way.

\begin{figure}[t]
  \centering
  \resizebox{\columnwidth}{!}{\input{figures/minf2.tex}}
  \caption{min-sum for $\mathcal{T}$ in the MS-IB decoder.}
  \label{fig:minf2}
\end{figure}
\autoref{fig:minf2} illustrates the $f$ block circuit for the MS-IB decoder. The binary form of a 4-bit message $t_{x}$ is denoted as $[t_{x,3},t_{x,2},t_{x,1},t_{x,0}]$. Thick lines indicate vectors of bits. By slight abuse of symbolism, the inverters with vectors as input and output carry out bitwise inversions.


\begin{figure}[t]
  \centering
  \resizebox{0.6\columnwidth}{!}{\input{figures/minf3.tex}}
  \caption{min-sum for $\mathcal{T}_{re}$ in the re-MS-IB decoder.}
  \label{fig:minf3}
  %\vspace{-10pt}
\end{figure}

\autoref{fig:minf3} illustrates the $f$ block circuit for the re-MS-IB variant. Comparing Figs.\,\ref{fig:minf2} and \ref{fig:minf3}, it can be seen that the critical path for the re-MS-IB variant of $f$ is much shorter than that of MS-IB. It consists of a single multiplexer as opposed to 3 multiplexers and 2 inverters. Furthermore, the amount of resources required is much less, as will be reflected in the results of Section\,\ref{sec:impl:cmp}.


\subsection{Error-correction Performance and Impact of Quantization}\label{sec:impl:ec-perf}
\begin{figure}
  \centering
  \input{figures/ecc-cmp.tex}
  \caption{Error-correction performance of the systematic $(128, 64)$ polar code.}
  \label{fig:ecc-cmp}
\end{figure}

\autoref{fig:ecc-cmp} shows the error-correction performance of the systematic $(128, 64)$ polar code our unrolled decoders support, modulated with \gls{bpsk} and transmitted over an \gls{awgn} channel.
Fixed-point results for $Q_i$.$Q_c=5.4$ and $Q_i$.$Q_c=4.4$ are presented as well as results for all \gls{lut}-based variants.
Floating-point results are also included for reference.
The $Q_i$.$Q_c=5.4$ fixed-point decoder and the MS-IB and re-MS-IB \gls{lut}-based variants are shown to have a coding loss of under 0.1\,dB at a \gls{fer} of $10^{-3}$ or at a \gls{ber} of $10^{-4}$ compared to the floating-point representation.
Meanwhile, the coding loss of the \gls{ib} \gls{lut}-based decoder is little under 0.13\,dB at the same \gls{ber} and \gls{fer} values. The \gls{lut}-based decoders initially have a smaller coding loss than the $Q_i$.$Q_c=5.4$ fixed-point decoder, but eventually come to match as the channel noise decreases.

\subsection{Comparison of the Unrolled Decoders}\label{sec:impl:cmp}
\begin{table}
  \centering
  \caption{Comparison of unrolled decoders for a systematic $(128,64)$ polar code. All decoders have an initiation interval of $10$.}
  \begin{tabular}{l c ccc}
    \toprule
                 & \bf Fixed point& \multicolumn{3}{c}{\bf \gls{lut} based} \\
    \midrule
    \textbf{Variant}      & - & IB & MS-IB & re-MS-IB \\
    \textbf{Area} (mm$^2$)&          0.090 & 0.254 & 0.218 & 0.069 \\ 
    \textbf{Frequency} (GHz)&        1.47 &  1.38 &  1.40 & 1.51 \\
    \textbf{Latency} (ns)&           58.6 &  62.2 &  61.3 & 56.8 \\ 
    \textbf{Info. T/P} (Gbps)&       9.40 &  8.85 &  8.98 & 9.68 \\ 
    \textbf{Area Eff.} (Gbps/mm$^2$)& 104.3 & 34.9 &  41.2 & 140.0 \\ 
    \bottomrule
  \end{tabular}
  \label{tab:cmp_asic}
\end{table}

\autoref{tab:cmp_asic} shows synthesis results using a 28\,nm FD-SOI CMOS technology from ST Microelectronics. All decoders were synthesized to target a clock frequency of 1.5\,GHz. The first column is for the $Q_i$.$Q_c=5.4$ fixed-point decoder and the last three for the 4-bit \gls{lut}-based decoders. 

We observe that our first and relatively naive \gls{lut}-based implementation (\gls{ib}) unfortunately has 182\% higher area and 6\% lower throughput than the baseline fixed-point decoder. The situation improves when using the $f$ block of \autoref{fig:minf2}. The MS-IB decoder requires 142\% higher area for a 4\% lower throughput compared to the fixed-point decoder. Finally, significant gains with respect to the baseline decoder are observed when applying the relabeling described in Section~\ref{sec:lut:variants}, where the resulting decoder, re-MS-IB, is 23\% smaller and 3\% faster than the fixed-point decoder, leading to a 35\% better area efficiency.

\section{Conclusion}\label{sec:conclusion}
In this work, we showed that replacing blocks of logic by \glspl{lut} in an unrolled decoder for polar codes may not necessarily lead to gains in terms of key performance metrics. We presented three variants of \gls{lut}-based decoders and compared them against a regular fixed-point decoder. We used a short systematic polar code to illustrate. Beyond carefully crafting the \glspl{lut}, the key ingredient to obtain good performance has been to determine \gls{lut} realizations having  truth tables that lead to efficient implementation. This was achieved by deploying the min-sum approximate \gls{lut} design together with appropriate relabeling of the inputs and output of \glspl{lut}. As a result, the third variant of the \gls{lut}-based decoders (re-MS-IB) was shown to outperform the baseline fixed-point decoder on all metrics, notably offering 35\% better area efficiency with similar or better error-correction performance.

\section*{Acknowledgement}
The authors would like to thank Marzieh Hashemipour Nazari (Eindhoven University of Technology) for providing the ASIC synthesis results. The work of Pascal Giard is supported by NSERC's Discovery Grant \#651824.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ConfAbrv,references}

\end{document}
